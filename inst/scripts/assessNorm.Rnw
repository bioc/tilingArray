%\VignetteIndexEntry{tilingArray - assess normalization}
%\VignetteDepends{tilingArray}
%\VignetteKeywords{normalization}
%\VignettePackage{tilingArray}

\documentclass[11pt]{article}
\usepackage{geometry}\usepackage{color}
\definecolor{darkblue}{rgb}{0.0,0.0,0.75}
\usepackage[%
baseurl={http://www.bioconductor.org},%
pdftitle={Assessing signal/noise ratio before and after normalization},%
pdfauthor={Wolfgang Huber},%
pdfsubject={tilingArray},%
pdfkeywords={Bioconductor},%
pagebackref,bookmarks,colorlinks,linkcolor=darkblue,citecolor=darkblue,%
pagecolor=darkblue,raiselinks,plainpages,pdftex]{hyperref}

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rfunction}[1]{{\small\texttt{#1}}}
\newcommand{\mbs}[1]{{\mbox{\scriptsize #1}}}

\newcommand{\myincfig}[3]{%
  \begin{figure}[htbp]
    \begin{center}
      \includegraphics[width=#2]{#1}
      \caption{\label{#1}#3}
    \end{center}
  \end{figure}
}

\begin{document}

%------------------------------------------------------------
\title{Assessing signal/noise ratio before and after normalization}
%------------------------------------------------------------
\author{Wolfgang Huber}
\maketitle
\tableofcontents

\section{Introduction}
The purpose of this document is to assess the performance of the
probe-response normalization by the function
\Rfunction{normalizeByReference} in the \Rpackage{tilingArray}
package. We use the example data from the David et
al.~\cite{David2006} paper, which is provided in the
\Rpackage{davidTiling} package.
%
<<load, results=hide>>=
library("tilingArray")
library("davidTiling")
if(!exists("davidTiling"))
  data("davidTiling")
@ 
%
<<errorReporting, echo=FALSE>>=
options(error=recover, warn=2, digits=3)
@ 
%
It contains \Sexpr{nrow(pData(davidTiling))} arrays with
\Sexpr{nrow(exprs(davidTiling))} features each. Three of them were hybridized to
genomic DNA, which will use as a reference for the normalization, and
five to RNA.
<<showDavidTilingData>>=
dim(exprs(davidTiling))
sampleNames(davidTiling)
@
%
Some of the computations in this vignette will take a long time and
require Gigabytes of RAM. I have sprinkled \Robject{cache()} and
\Robject{if(exists(...))} statements around the most massive
computations -- this is simply so that during the writing of the
vignette I can rerun \Rfunction{Sweave} on it in an incremental
fashion without always having to redo all computations from
scratch. Eventually they will go away, and for the comprehension of
the computations they are irrelevant.

%--------------------------------------------------
\section{Selection of PM and background features}
%---------------------------------------------------
The design of the chip includes about 3 Mio \emph{perfect match
probes}, about 3 Mio \emph{mismatch probes}, and a few thousand
controls. The \Robject{probeAnno} object contains annotations for each
probe. It was obtained by aligning the probe sequence to the genomic
sequence of S. cerevisiae in August 2005. Please see its manual page
and the script \texttt{makeProbeAnno.R} in the \Rpackage{davidTiling}
package for details.
%
<<probeAnno>>=
if(!exists("probeAnno"))
  data("probeAnno")
@ 
%
We define two logical vectors: \Robject{isPM} is \Robject{TRUE} if a
probe has a perfect match anywhere in the genome, \Robject{isBG} is
\Robject{TRUE} if that match is outside any annotated feature on 
either strand.
%
<<isPM>>=
isPM = logical(nrow(exprs(davidTiling)))
for(j in probeAnno$probeReverse)
  isPM[ as.character(j) != ""] = TRUE
isBG = (probeAnno$probeReverse$no_feature=="no" &
        probeAnno$probeDirect$no_feature=="no")
@
<<table, print=TRUE>>=
sum(isPM)
tab=table(isPM, isBG)
@ 
%
There are \Sexpr{tab["FALSE", "FALSE"]} mismatch probes, whose signal
we will not try to normalize, since we only have meaningful reference
intensities for the \Sexpr{sum(isPM)} perfect match probes.  For the
background estimation, we will use the \Sexpr{tab["TRUE", "TRUE"]}
features for which we expect no specific signal. Some of them will
indeed have specific signal, due to new transcripts that were not yet
annotated in SGD in August 2005; but this is not a concern, since we
will only use statistical properties of the signal distribution that are
insensitive to a small set of outliers. Alternatively, as we show
below, we could also use the signal from the MM probes for background
estimation.

%----------------------------------------
\section{Normalization}
We select the 5 arrays that had RNA hybridized to them and the 3
arrays that had DNA hybridized to them. We want to normalize the
intensity readings from the former by using the latter as a reference.
%
<<selectArrays>>=
isRNA = davidTiling$nucleicAcid %in% c("poly(A) RNA","total RNA")
isDNA = davidTiling$nucleicAcid %in% "genomic DNA"
stopifnot(sum(isRNA)==5, sum(isDNA)==3)
@ 

<<normalizeByReference>>=
pfn = sprintf("assessNorm-normalize%d.pdf", seq(along=which(isRNA)))
if(!exists("xn2"))
  xn2 = cache("xn2",
    normalizeByReference(davidTiling[,isRNA], davidTiling[,isDNA], 
                         pm=isPM, background=isBG,
                         plotFileNames=pfn))
@
 
%----------------------------------------
\section{Alternative normalization methods}
\subsection{Without dropping the worst 5\% probes}
For comparison, we also compare to the situation in which 
we do not throw out the weakest features, by setting 
\Robject{cutoffQuantile=0}.
<<normalizeWithoutThrowout>>=
if(!exists("xn1"))
  xn1 = cache("xn1",
    normalizeByReference(davidTiling[,isRNA], davidTiling[,isDNA], 
                         pm=isPM, background=isBG, cutoffQuantile=0))
@ 
%

\subsection{Background correction by MM}
Instead of the background correction based on ``similar'' no-target
probes that is done in \Rfunction{normalizeByReference}, we can also
consider background correction by MM probes.

There is a slight complication: the set of probes that we are
considering as PM in this document is somewhat different from those
that went into the design of PM/MM pairs on the array, since different
versions of the yeast genome sequence were used. We take the
intersection. For this, we determine the indices of the designed PM/MM
pairs. The array has 2560 rows and 2560 columns. If we count the rows
and columns from 0 to 2559, then the linear indices of the features
(e.\,g.\, in the expression matrix of the \Rclass{eSet}
\Robject{davidTiling}) are given by r*2560+c. The PM features lie in
rows $1, 3, \ldots, 2557$, their corresponding MM features in rows $2,
4, \ldots, 2558$. We are going to use this information, as well as the
probe sequences that are provided in the
\Rpackage{Scerevisiaetilingprobe} package.
%
<<PMMMpairs>>=
library("Scerevisiaetilingprobe")

nc = as.integer(2560)
stopifnot(nc*nc==nrow(davidTiling))

ipm = rep(as.integer(seq(1, nc-3, by=2)), each=nc) * nc + (1:nc)
seqPM = Scerevisiaetilingprobe$sequence[ipm]
seqMM = Scerevisiaetilingprobe$sequence[ipm+nc]
ispair = (!is.na(seqPM) & !is.na(seqMM) & (seqPM==complementSeq(seqMM, start=13, stop=13)))

@ 
%
We see that out of the \Sexpr{length(ipm)} probes in odd-numbered
rows, listed by \Robject{ipm}, most do indeed have a corresponding
mismatch probe in the row below.
%
@
<<ispair,print=TRUE>>=
length(ispair)
table(ispair)
@ 
%
We define vectors \Robject{PMind} and \Robject{MMind} that contain the
indices of PM/MM pairs,
%
<<PMind>>=
PMind = ipm[ispair]
MMind = PMind + nc
@ 
%
and a function \Rfunction{normalizeByReferenceWithMM} that is similar
to \Rfunction{normalizeByReference} in the \Rpackage{tilingArray}
package, except for that for each PM probe it uses the corresponding
MM value for the background correction rather than the background
estimator that is used in \Rfunction{normalizeByReference}.
%
<<PMMMnormalize>>=
normalizeByReferenceWithMM = function(x, reference, pm, mm, cutoffQuantile=0.05) {
  refSig = 2^rowMeans(log2(exprs(reference)[pm,]))

  xn = (exprs(x)[pm,] - exprs(x)[mm,]) / refSig
  vsnres = vsn(xn, lts.quantile=0.95, subsample=2e5, verbose=FALSE)
  yn = exprs(vsnres)/log(2)
  
  throwOut = (refSig < quantile(refSig, probs=cutoffQuantile))
  yn[throwOut, ] = NA

  res = matrix(as.numeric(NA), nrow=nrow(x), ncol=ncol(yn))
  res[pm, ] = yn
  
  return(res)
}

xwmm = cache("xwmm",
  normalizeByReferenceWithMM(davidTiling[, isRNA], davidTiling[, isDNA], PMind, MMind)) 
@ 

%----------------------------------------
\section{Assessment}
\subsection{Visually}

We would like to visualize the data along genomic coordinates. We
select the features that map to the ``-'' strand of chromosome 9. 
The integer vectors \Robject{sta} and \Robject{end} contain the start
and end coordinate of their match, \Robject{ind} their indices in the array
\Robject{exprs(davidTiling)}.
%
<<stainduni>>=
sta = probeAnno$"9.-.start"
end = probeAnno$"9.-.end"
ind = probeAnno$"9.-.index"
@ 
%
We construct a list of vectors, each containing different versions of
the intensity data, in order that corresponds to \Robject{sta} and
\Robject{ind} from above.
<<setUpDifferentNormMethods>>=
dat = vector(mode="list", length=5)
dat[[1]] = log2(exprs(davidTiling)[ind, which(isDNA)[1]])
dat[[2]] = log2(exprs(davidTiling)[ind, which(isRNA)[1]])
dat[[3]] = dat[[2]]-dat[[1]]
dat[[4]] = exprs(xn1)[ind, 1]
dat[[5]] = exprs(xn2)[ind, 1]
dat[[6]] = xwmm[ind, 1]
for(j in 3:length(dat))
  dat[[j]] = dat[[j]] - quantile(dat[[j]], 0.05, na.rm=TRUE)
names(dat) = letters[seq(along=dat)]
@ 
%
We select a 10kB region around the highly expressed genes RPN2 and SER33
to fit on a plot, and set the $y$-axis limits:
<<selectRegionForPlot>>=
sel = (sta>=216600 & end<=227000)
ysc = sapply(dat, function(py) quantile(py, probs=c(0, 1), na.rm=TRUE))
ysc[, 3:6] = c(-3,8)
@ 
%
Now we are ready to plot:
<<alongChromPlot, fig=TRUE, include=FALSE, height=10, width=7>>=
anno = data.frame(start=c(217860, 221078),
                  end  =c(220697, 222487),
                  name =I(c("RPN2", "SER33")))
ticks = c(217, 223, 224, 225, 226)
comparisonPlot((sta+end)[sel]/2, lapply(dat, "[", sel), yscale=ysc, 
  anno=anno, ticks=ticks, cex=0.2)
@ 
%
The result is shown in Figure~\ref{assessNorm-alongChromPlot}.  
It shows scatterplots of
different types of signal ($y$-axis) along genomic coordinates
($x$-axis). Each dot corresponds to a microarray feature.  Note how
the signal distributions in panels b)-f) vary both with respect to the
variability within transcribed and untranscribed segments, and
in the amplitude between them.
a) signal from one of the DNA hybridizations (logarithmic scale, base 2).  
The $y$-coordinate of each dot is also encoded using
a pseudo-color scheme. Dark red corresponds to features that have a 
very weak response, dark blue to those with the strongest response.
The same coloring is also used in panels b)-f).
b) unnormalized intensities from one of the poly(A) RNA bybridizations
(logarithmic scale, base 2).  
c) Divide RNA-signal by DNA-signal then take logarithm (base 2). 
d) Background subtraction of the RNA-signal, divide by DNA-signal, then 
variance stabilizing normalization (vsn, glog base 2). 
e) In addition to d), drop the 5\% weakest features in the DNA hybridization. 
f) Similar to e), but using the MM probes for background correction instead.

\myincfig{assessNorm-alongChromPlot}{0.96\textwidth}{% 
Along-chromosome plots of the data for different normalization methods. 
Please see text.}

Now here's a bit of a hack: the plot symbols are too big if the plot is
produced as above, and somehow the PDF and EPS drivers of R ignore the
\Robject{cex} parameter.  However, one can open the EPS file and
replace all occurences of the string ``3.00'' by ``1.00''.
%
<<repairEPS, results=hide>>=
writeLines(sub("3.00", "1.00", readLines("assessNorm-alongChromPlot.eps"), fixed=TRUE),
  con=("assessNorm-tmp.eps"))
system("ps2pdf assessNorm-tmp.eps assessNorm-alongChromPlot.pdf")
@ 


%----------------------------------------
\subsection{Quantitatively}

In order to assess to quantitatively assess the results of
normalization, we consider a signal/noise ratio. Note that only
looking at one or another (signal, or noise) by itself could be
misleading. 

We define a set of control regions, which correspond to either highly
expressed transcripts (\Robject{positiveCtrls}) or untranscribed
intergenic regions (\Robject{negativeCtrls}). The assumption is that
the signal within a region should be constant, and deviations from
that are ``noise'', while the difference between positve and negative
controls should be large, and is counted as ``signal''.

<<defineControls>>=
positiveCtrls = cbind(c(217860,220697), ## RPN2
                      c(221078,222487)) ## SER33 	.
negativeCtrls = cbind(c(216800, 217700),
                      c(222800, 227000)) ## SPO22
@ 
%
Noise $\sigma$ is calculated as the 
% weighted 
average of the differences between 97.5\% and 2.5\% quantiles of the
data within each of the control regions. The range between the 97.5\%
and 2.5\% quantiles contains 95\% of the data, while 5\% is outside
the range.
\begin{equation}
\sigma = \frac{1}{Q^{0.975}_N-Q^{0.025}_N}
\cdot\frac%
{\displaystyle\sum_{r\in\{\mbs{pos},\mbs{neg}\}}Q^{0.975}_r-Q^{0.025}_r}
{\displaystyle|\{\mbs{pos},\mbs{neg}\}|}.
%{\displaystyle\sum_{r\in\{\mbs{pos},\mbs{neg}\}}n_r\left(Q^{0.975}_r-Q^{0.025}_r\right)}
%{\displaystyle\sum_{r\in\{\mbs{pos},\mbs{neg}\}}n_r}.
\end{equation}
Here, the symbol $r$ counts over the different regions.
% and $n_r$ is the number of probes representing that region. 
The constant in the denominator is the differences between 95\% and
5\% quantiles for the standard Normal distribution, hence $\sigma$ is
equal to 1 if the data come from the standard Normal distribution.

Signal $\Delta\mu$ is calculated as the difference between the 
% weighted 
averages of the means of positive and negative control regions.
\begin{equation}
\Delta\mu =
\frac{\displaystyle\sum_{r\in\{\mbs{pos}\}}\mu_r}{\displaystyle|\{\mbs{pos}\}|} -
\frac{\displaystyle\sum_{r\in\{\mbs{neg}\}}\mu_r}{\displaystyle|\{\mbs{neg}\}|}.
%\frac{\displaystyle\sum_{r\in\{\mbs{pos}\}} n_r \mu_r}{\displaystyle\sum_{r\in\{\mbs{pos}\}}n_r} -
%\frac{\displaystyle\sum_{r\in\{\mbs{neg}\}} n_r \mu_r}{\displaystyle\sum_{r\in\{\mbs{neg}\}}n_r}.
\end{equation}

I have explored many variations of this calculation, using different
definitions of $\sigma$, $\Delta\mu$, and of the control regions. The
ranking (relative order) of the methods was always the same as shown
in the following.
%
<<defineWithinAndBetween>>=
fac = 2*qnorm(0.975)

withinAndBetween = function(x, ...) {
  meanAndSd = function(region, dohist=FALSE) {
    d = x[(sta>=region[1]) & (end<=region[2]) & !is.na(x)]
    res = c(mean(d), diff(quantile(d, c(0.025, 0.975)))/fac, length(d)) 
    if(dohist) hist(d, 20, main=paste(signif(res, 3)), col="orange")
    res
  }
  p = apply(positiveCtrls, 2, meanAndSd, ...)
  n = apply(negativeCtrls, 2, meanAndSd, ...)
  dmu =  sum(p[1,]*p[3,])/sum(p[3,]) - sum(n[1,]*n[3,])/sum(n[3,])
  sig = (sum(p[2,]*p[3,])+sum(n[2,]*n[3,])) / (sum(p[3,])+sum(n[3,]))
  return(c("S/N"=dmu/sig, "S"=dmu, "N"=sig))
}
@ 
<<applyWithinAndBetween, print=TRUE>>=
sn = sapply(dat[2:6], withinAndBetween, dohist=TRUE)
@ 
<<applyWithinAndBetween, eval=FALSE, echo=FALSE, eps=FALSE, fig=TRUE, include=FALSE>>=
par(mfcol=c(4,5))
sn = sapply(dat[2:6], withinAndBetween, dohist=TRUE)
sn
@ 
%
%For excruciating detail, the histograms of the individual
%distributions are also shown in Figure~\ref{assessNorm-applyWithinAndBetween}. 

%\myincfig{assessNorm-applyWithinAndBetween}{\textwidth}{
%Histograms of the probe intensity distribution for each of the 4 
%control regions (rows) and the 5 methods b)-f) (columns).
%}


%------------------------------------------------------------
\begin{thebibliography}{10}

\bibitem{David2006} Lior David, Wolfgang Huber, Marina Granovskaia,
Joern Toedling, Curtis J. Palm, Lee Bofkin, Ted Jones, Ronald
W. Davis, and Lars M. Steinmetz \newblock A high-resolution map of
transcription in the yeast genome.  \newblock \textit{PNAS}, 2006.

\end{thebibliography}

\end{document}
